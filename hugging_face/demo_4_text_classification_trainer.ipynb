{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from datasets import (load_dataset, load_from_disk, Dataset)\n",
    "from transformers import (AutoTokenizer, AutoModel, BertTokenizer, BertModel,\n",
    "                          AutoModelForCausalLM, AutoModelForSequenceClassification,\n",
    "                          BitsAndBytesConfig, TrainingArguments,\n",
    "                          DataCollatorWithPadding, DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForSeq2Seq, DataCollatorForTokenClassification,\n",
    "                          Trainer)\n",
    "from sklearn.metrics import (recall_score, precision_score, f1_score, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda; devive_cnt = 1\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "devive_cnt = th.cuda.device_count()\n",
    "print(f\"device = {device}; devive_cnt = {devive_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = os.getcwd()\n",
    "path_data = os.path.join(os.path.dirname(path_project), \"data\")\n",
    "path_model = os.path.join(os.path.dirname(path_project), \"model\")\n",
    "path_output = os.path.join(os.path.dirname(path_project), \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-1: 载入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"axb/super_glue-test.arrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接用 load_dataset 加载\n",
    "dataset = load_dataset(\n",
    "            path=\"arrow\",\n",
    "            data_files=os.path.join(path_data, filename),\n",
    "            split=\"all\"\n",
    "        )\n",
    "dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"label\", shuffle=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'idx', 'label'],\n",
       "        num_rows: 883\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'idx', 'label'],\n",
       "        num_rows: 221\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-2: tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-large-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-3: 配置量化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    # load_in_4bit=True,\n",
    "    # bnb_4bit_quant_type=\"nf4\",\n",
    "    # bnb_4bit_compute_dtype=th.bfloat16,\n",
    "    # bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-4: 载入基础大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at c:\\my_project\\MyGit\\Machine-Learning-Column\\model\\bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_base = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    # device_map=\"auto\",\n",
    "    # torch_dtype=th.float16,\n",
    "    # quantization_config=config_bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  name: bert.embeddings.word_embeddings.weight;  shape: torch.Size([30522, 1024]);  dtype: torch.float32;  device: cpu\n",
      "1  name: bert.embeddings.position_embeddings.weight;  shape: torch.Size([512, 1024]);  dtype: torch.float32;  device: cpu\n",
      "2  name: bert.embeddings.token_type_embeddings.weight;  shape: torch.Size([2, 1024]);  dtype: torch.float32;  device: cpu\n",
      "3  name: bert.embeddings.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "4  name: bert.embeddings.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "5  name: bert.encoder.layer.0.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "6  name: bert.encoder.layer.0.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "7  name: bert.encoder.layer.0.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "8  name: bert.encoder.layer.0.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "9  name: bert.encoder.layer.0.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "10  name: bert.encoder.layer.0.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "11  name: bert.encoder.layer.0.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "12  name: bert.encoder.layer.0.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "13  name: bert.encoder.layer.0.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "14  name: bert.encoder.layer.0.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "15  name: bert.encoder.layer.0.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "16  name: bert.encoder.layer.0.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "17  name: bert.encoder.layer.0.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "18  name: bert.encoder.layer.0.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "19  name: bert.encoder.layer.0.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "20  name: bert.encoder.layer.0.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "21  name: bert.encoder.layer.1.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "22  name: bert.encoder.layer.1.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "23  name: bert.encoder.layer.1.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "24  name: bert.encoder.layer.1.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "25  name: bert.encoder.layer.1.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "26  name: bert.encoder.layer.1.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "27  name: bert.encoder.layer.1.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "28  name: bert.encoder.layer.1.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "29  name: bert.encoder.layer.1.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "30  name: bert.encoder.layer.1.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "31  name: bert.encoder.layer.1.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "32  name: bert.encoder.layer.1.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "33  name: bert.encoder.layer.1.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "34  name: bert.encoder.layer.1.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "35  name: bert.encoder.layer.1.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "36  name: bert.encoder.layer.1.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "37  name: bert.encoder.layer.2.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "38  name: bert.encoder.layer.2.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "39  name: bert.encoder.layer.2.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "40  name: bert.encoder.layer.2.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "41  name: bert.encoder.layer.2.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "42  name: bert.encoder.layer.2.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "43  name: bert.encoder.layer.2.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "44  name: bert.encoder.layer.2.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "45  name: bert.encoder.layer.2.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "46  name: bert.encoder.layer.2.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "47  name: bert.encoder.layer.2.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "48  name: bert.encoder.layer.2.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "49  name: bert.encoder.layer.2.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "50  name: bert.encoder.layer.2.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "51  name: bert.encoder.layer.2.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "52  name: bert.encoder.layer.2.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "53  name: bert.encoder.layer.3.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "54  name: bert.encoder.layer.3.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "55  name: bert.encoder.layer.3.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "56  name: bert.encoder.layer.3.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "57  name: bert.encoder.layer.3.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "58  name: bert.encoder.layer.3.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "59  name: bert.encoder.layer.3.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "60  name: bert.encoder.layer.3.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "61  name: bert.encoder.layer.3.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "62  name: bert.encoder.layer.3.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "63  name: bert.encoder.layer.3.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "64  name: bert.encoder.layer.3.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "65  name: bert.encoder.layer.3.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "66  name: bert.encoder.layer.3.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "67  name: bert.encoder.layer.3.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "68  name: bert.encoder.layer.3.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "69  name: bert.encoder.layer.4.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "70  name: bert.encoder.layer.4.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "71  name: bert.encoder.layer.4.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "72  name: bert.encoder.layer.4.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "73  name: bert.encoder.layer.4.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "74  name: bert.encoder.layer.4.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "75  name: bert.encoder.layer.4.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "76  name: bert.encoder.layer.4.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "77  name: bert.encoder.layer.4.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "78  name: bert.encoder.layer.4.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "79  name: bert.encoder.layer.4.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "80  name: bert.encoder.layer.4.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "81  name: bert.encoder.layer.4.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "82  name: bert.encoder.layer.4.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "83  name: bert.encoder.layer.4.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "84  name: bert.encoder.layer.4.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "85  name: bert.encoder.layer.5.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "86  name: bert.encoder.layer.5.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "87  name: bert.encoder.layer.5.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "88  name: bert.encoder.layer.5.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "89  name: bert.encoder.layer.5.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "90  name: bert.encoder.layer.5.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "91  name: bert.encoder.layer.5.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "92  name: bert.encoder.layer.5.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "93  name: bert.encoder.layer.5.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "94  name: bert.encoder.layer.5.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "95  name: bert.encoder.layer.5.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "96  name: bert.encoder.layer.5.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "97  name: bert.encoder.layer.5.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "98  name: bert.encoder.layer.5.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "99  name: bert.encoder.layer.5.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "100  name: bert.encoder.layer.5.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "101  name: bert.encoder.layer.6.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "102  name: bert.encoder.layer.6.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "103  name: bert.encoder.layer.6.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "104  name: bert.encoder.layer.6.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "105  name: bert.encoder.layer.6.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "106  name: bert.encoder.layer.6.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "107  name: bert.encoder.layer.6.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "108  name: bert.encoder.layer.6.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "109  name: bert.encoder.layer.6.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "110  name: bert.encoder.layer.6.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "111  name: bert.encoder.layer.6.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "112  name: bert.encoder.layer.6.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "113  name: bert.encoder.layer.6.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "114  name: bert.encoder.layer.6.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "115  name: bert.encoder.layer.6.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "116  name: bert.encoder.layer.6.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "117  name: bert.encoder.layer.7.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "118  name: bert.encoder.layer.7.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "119  name: bert.encoder.layer.7.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "120  name: bert.encoder.layer.7.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "121  name: bert.encoder.layer.7.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "122  name: bert.encoder.layer.7.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "123  name: bert.encoder.layer.7.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "124  name: bert.encoder.layer.7.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "125  name: bert.encoder.layer.7.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "126  name: bert.encoder.layer.7.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "127  name: bert.encoder.layer.7.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "128  name: bert.encoder.layer.7.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "129  name: bert.encoder.layer.7.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "130  name: bert.encoder.layer.7.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "131  name: bert.encoder.layer.7.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "132  name: bert.encoder.layer.7.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "133  name: bert.encoder.layer.8.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "134  name: bert.encoder.layer.8.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "135  name: bert.encoder.layer.8.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "136  name: bert.encoder.layer.8.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "137  name: bert.encoder.layer.8.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "138  name: bert.encoder.layer.8.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "139  name: bert.encoder.layer.8.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "140  name: bert.encoder.layer.8.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "141  name: bert.encoder.layer.8.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "142  name: bert.encoder.layer.8.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "143  name: bert.encoder.layer.8.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "144  name: bert.encoder.layer.8.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "145  name: bert.encoder.layer.8.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "146  name: bert.encoder.layer.8.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "147  name: bert.encoder.layer.8.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "148  name: bert.encoder.layer.8.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "149  name: bert.encoder.layer.9.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "150  name: bert.encoder.layer.9.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "151  name: bert.encoder.layer.9.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "152  name: bert.encoder.layer.9.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "153  name: bert.encoder.layer.9.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "154  name: bert.encoder.layer.9.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "155  name: bert.encoder.layer.9.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "156  name: bert.encoder.layer.9.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "157  name: bert.encoder.layer.9.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "158  name: bert.encoder.layer.9.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "159  name: bert.encoder.layer.9.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "160  name: bert.encoder.layer.9.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "161  name: bert.encoder.layer.9.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "162  name: bert.encoder.layer.9.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "163  name: bert.encoder.layer.9.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "164  name: bert.encoder.layer.9.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "165  name: bert.encoder.layer.10.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "166  name: bert.encoder.layer.10.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "167  name: bert.encoder.layer.10.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "168  name: bert.encoder.layer.10.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "169  name: bert.encoder.layer.10.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "170  name: bert.encoder.layer.10.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "171  name: bert.encoder.layer.10.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "172  name: bert.encoder.layer.10.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "173  name: bert.encoder.layer.10.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "174  name: bert.encoder.layer.10.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "175  name: bert.encoder.layer.10.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "176  name: bert.encoder.layer.10.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "177  name: bert.encoder.layer.10.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "178  name: bert.encoder.layer.10.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "179  name: bert.encoder.layer.10.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "180  name: bert.encoder.layer.10.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "181  name: bert.encoder.layer.11.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "182  name: bert.encoder.layer.11.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "183  name: bert.encoder.layer.11.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "184  name: bert.encoder.layer.11.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "185  name: bert.encoder.layer.11.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "186  name: bert.encoder.layer.11.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "187  name: bert.encoder.layer.11.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "188  name: bert.encoder.layer.11.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "189  name: bert.encoder.layer.11.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "190  name: bert.encoder.layer.11.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "191  name: bert.encoder.layer.11.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "192  name: bert.encoder.layer.11.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "193  name: bert.encoder.layer.11.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "194  name: bert.encoder.layer.11.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "195  name: bert.encoder.layer.11.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "196  name: bert.encoder.layer.11.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "197  name: bert.encoder.layer.12.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "198  name: bert.encoder.layer.12.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "199  name: bert.encoder.layer.12.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "200  name: bert.encoder.layer.12.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "201  name: bert.encoder.layer.12.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "202  name: bert.encoder.layer.12.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "203  name: bert.encoder.layer.12.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "204  name: bert.encoder.layer.12.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "205  name: bert.encoder.layer.12.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "206  name: bert.encoder.layer.12.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "207  name: bert.encoder.layer.12.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "208  name: bert.encoder.layer.12.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "209  name: bert.encoder.layer.12.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "210  name: bert.encoder.layer.12.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "211  name: bert.encoder.layer.12.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "212  name: bert.encoder.layer.12.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "213  name: bert.encoder.layer.13.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "214  name: bert.encoder.layer.13.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "215  name: bert.encoder.layer.13.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "216  name: bert.encoder.layer.13.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "217  name: bert.encoder.layer.13.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "218  name: bert.encoder.layer.13.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "219  name: bert.encoder.layer.13.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "220  name: bert.encoder.layer.13.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "221  name: bert.encoder.layer.13.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "222  name: bert.encoder.layer.13.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "223  name: bert.encoder.layer.13.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "224  name: bert.encoder.layer.13.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "225  name: bert.encoder.layer.13.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "226  name: bert.encoder.layer.13.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "227  name: bert.encoder.layer.13.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "228  name: bert.encoder.layer.13.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "229  name: bert.encoder.layer.14.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "230  name: bert.encoder.layer.14.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "231  name: bert.encoder.layer.14.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "232  name: bert.encoder.layer.14.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "233  name: bert.encoder.layer.14.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "234  name: bert.encoder.layer.14.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "235  name: bert.encoder.layer.14.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "236  name: bert.encoder.layer.14.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "237  name: bert.encoder.layer.14.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "238  name: bert.encoder.layer.14.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "239  name: bert.encoder.layer.14.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "240  name: bert.encoder.layer.14.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "241  name: bert.encoder.layer.14.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "242  name: bert.encoder.layer.14.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "243  name: bert.encoder.layer.14.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "244  name: bert.encoder.layer.14.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "245  name: bert.encoder.layer.15.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "246  name: bert.encoder.layer.15.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "247  name: bert.encoder.layer.15.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "248  name: bert.encoder.layer.15.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "249  name: bert.encoder.layer.15.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "250  name: bert.encoder.layer.15.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "251  name: bert.encoder.layer.15.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "252  name: bert.encoder.layer.15.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "253  name: bert.encoder.layer.15.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "254  name: bert.encoder.layer.15.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "255  name: bert.encoder.layer.15.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "256  name: bert.encoder.layer.15.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "257  name: bert.encoder.layer.15.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "258  name: bert.encoder.layer.15.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "259  name: bert.encoder.layer.15.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "260  name: bert.encoder.layer.15.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "261  name: bert.encoder.layer.16.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "262  name: bert.encoder.layer.16.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "263  name: bert.encoder.layer.16.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "264  name: bert.encoder.layer.16.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "265  name: bert.encoder.layer.16.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "266  name: bert.encoder.layer.16.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "267  name: bert.encoder.layer.16.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "268  name: bert.encoder.layer.16.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "269  name: bert.encoder.layer.16.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "270  name: bert.encoder.layer.16.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "271  name: bert.encoder.layer.16.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "272  name: bert.encoder.layer.16.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "273  name: bert.encoder.layer.16.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "274  name: bert.encoder.layer.16.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "275  name: bert.encoder.layer.16.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "276  name: bert.encoder.layer.16.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "277  name: bert.encoder.layer.17.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "278  name: bert.encoder.layer.17.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "279  name: bert.encoder.layer.17.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "280  name: bert.encoder.layer.17.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "281  name: bert.encoder.layer.17.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "282  name: bert.encoder.layer.17.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "283  name: bert.encoder.layer.17.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "284  name: bert.encoder.layer.17.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "285  name: bert.encoder.layer.17.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "286  name: bert.encoder.layer.17.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "287  name: bert.encoder.layer.17.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "288  name: bert.encoder.layer.17.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "289  name: bert.encoder.layer.17.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "290  name: bert.encoder.layer.17.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "291  name: bert.encoder.layer.17.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "292  name: bert.encoder.layer.17.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "293  name: bert.encoder.layer.18.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "294  name: bert.encoder.layer.18.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "295  name: bert.encoder.layer.18.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "296  name: bert.encoder.layer.18.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "297  name: bert.encoder.layer.18.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "298  name: bert.encoder.layer.18.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "299  name: bert.encoder.layer.18.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "300  name: bert.encoder.layer.18.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "301  name: bert.encoder.layer.18.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "302  name: bert.encoder.layer.18.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "303  name: bert.encoder.layer.18.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "304  name: bert.encoder.layer.18.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "305  name: bert.encoder.layer.18.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "306  name: bert.encoder.layer.18.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "307  name: bert.encoder.layer.18.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "308  name: bert.encoder.layer.18.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "309  name: bert.encoder.layer.19.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "310  name: bert.encoder.layer.19.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "311  name: bert.encoder.layer.19.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "312  name: bert.encoder.layer.19.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "313  name: bert.encoder.layer.19.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "314  name: bert.encoder.layer.19.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "315  name: bert.encoder.layer.19.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "316  name: bert.encoder.layer.19.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "317  name: bert.encoder.layer.19.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "318  name: bert.encoder.layer.19.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "319  name: bert.encoder.layer.19.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "320  name: bert.encoder.layer.19.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "321  name: bert.encoder.layer.19.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "322  name: bert.encoder.layer.19.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "323  name: bert.encoder.layer.19.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "324  name: bert.encoder.layer.19.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "325  name: bert.encoder.layer.20.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "326  name: bert.encoder.layer.20.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "327  name: bert.encoder.layer.20.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "328  name: bert.encoder.layer.20.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "329  name: bert.encoder.layer.20.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "330  name: bert.encoder.layer.20.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "331  name: bert.encoder.layer.20.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "332  name: bert.encoder.layer.20.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "333  name: bert.encoder.layer.20.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "334  name: bert.encoder.layer.20.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "335  name: bert.encoder.layer.20.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "336  name: bert.encoder.layer.20.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "337  name: bert.encoder.layer.20.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "338  name: bert.encoder.layer.20.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "339  name: bert.encoder.layer.20.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "340  name: bert.encoder.layer.20.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "341  name: bert.encoder.layer.21.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "342  name: bert.encoder.layer.21.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "343  name: bert.encoder.layer.21.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "344  name: bert.encoder.layer.21.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "345  name: bert.encoder.layer.21.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "346  name: bert.encoder.layer.21.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "347  name: bert.encoder.layer.21.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "348  name: bert.encoder.layer.21.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "349  name: bert.encoder.layer.21.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "350  name: bert.encoder.layer.21.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "351  name: bert.encoder.layer.21.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "352  name: bert.encoder.layer.21.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "353  name: bert.encoder.layer.21.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "354  name: bert.encoder.layer.21.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "355  name: bert.encoder.layer.21.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "356  name: bert.encoder.layer.21.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "357  name: bert.encoder.layer.22.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "358  name: bert.encoder.layer.22.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "359  name: bert.encoder.layer.22.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "360  name: bert.encoder.layer.22.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "361  name: bert.encoder.layer.22.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "362  name: bert.encoder.layer.22.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "363  name: bert.encoder.layer.22.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "364  name: bert.encoder.layer.22.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "365  name: bert.encoder.layer.22.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "366  name: bert.encoder.layer.22.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "367  name: bert.encoder.layer.22.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "368  name: bert.encoder.layer.22.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "369  name: bert.encoder.layer.22.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "370  name: bert.encoder.layer.22.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "371  name: bert.encoder.layer.22.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "372  name: bert.encoder.layer.22.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "373  name: bert.encoder.layer.23.attention.self.query.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "374  name: bert.encoder.layer.23.attention.self.query.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "375  name: bert.encoder.layer.23.attention.self.key.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "376  name: bert.encoder.layer.23.attention.self.key.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "377  name: bert.encoder.layer.23.attention.self.value.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "378  name: bert.encoder.layer.23.attention.self.value.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "379  name: bert.encoder.layer.23.attention.output.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "380  name: bert.encoder.layer.23.attention.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "381  name: bert.encoder.layer.23.attention.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "382  name: bert.encoder.layer.23.attention.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "383  name: bert.encoder.layer.23.intermediate.dense.weight;  shape: torch.Size([4096, 1024]);  dtype: torch.float32;  device: cpu\n",
      "384  name: bert.encoder.layer.23.intermediate.dense.bias;  shape: torch.Size([4096]);  dtype: torch.float32;  device: cpu\n",
      "385  name: bert.encoder.layer.23.output.dense.weight;  shape: torch.Size([1024, 4096]);  dtype: torch.float32;  device: cpu\n",
      "386  name: bert.encoder.layer.23.output.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "387  name: bert.encoder.layer.23.output.LayerNorm.weight;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "388  name: bert.encoder.layer.23.output.LayerNorm.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "389  name: bert.pooler.dense.weight;  shape: torch.Size([1024, 1024]);  dtype: torch.float32;  device: cpu\n",
      "390  name: bert.pooler.dense.bias;  shape: torch.Size([1024]);  dtype: torch.float32;  device: cpu\n",
      "391  name: classifier.weight;  shape: torch.Size([2, 1024]);  dtype: torch.float32;  device: cpu\n",
      "392  name: classifier.bias;  shape: torch.Size([2]);  dtype: torch.float32;  device: cpu\n"
     ]
    }
   ],
   "source": [
    "for i, (name, parm) in enumerate(model_base.named_parameters()):\n",
    "    print(f\"{i}  name: {name};  shape: {parm.shape};  dtype: {parm.dtype};  device: {parm.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, param) in model_base.named_parameters():\n",
    "    if name.startswith(\"bert\"):\n",
    "        param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-5: 定义整理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: text classification\n",
    "def tokenize_function(sample):\n",
    "    inputs = tokenizer(text=sample[\"sentence1\"], text_pair=sample[\"sentence2\"], max_length=512, truncation=True)\n",
    "    inputs[\"labels\"] = sample[\"label\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: text generation\n",
    "# def tokenize_function(sample):\n",
    "#     inputs = tokenizer(text=sample[\"query\"], max_length=512, truncation=True)\n",
    "#     labels = tokenizer(text_target=sample[\"response\"], max_length=128, truncation=True)\n",
    "#     inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task: text generation-glm\n",
    "# def tokenize_function(sample):\n",
    "#     inputs = tokenizer(text=sample[\"query\"], max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "#     inputs = tokenizer.build_inputs_for_generation(inputs, target=sample[\"response\"], max_gen_length=128, padding=True)\n",
    "#     return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenized = dataset.map(tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 883\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 221\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_tokenized = dataset_tokenized[\"train\"]\n",
    "dataset_test_tokenized = dataset_tokenized[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn = DataCollatorForLanguageModeling(tokenizer, mlm=False) \n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "# collate_fn = DataCollatorForSeq2Seq(tokenizer, padding=True)\n",
    "# collate_fn = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-6: 配置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = {\n",
    "    \"embedding_dim\": 1024,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dropout\": 0.2,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"gradient_steps\": 1,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_seq_lenght\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-7: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sft = model_base.to(device)\n",
    "model_sft.gradient_checkpointing_enable() \n",
    "model_sft.enable_input_require_grads()\n",
    "model_sft.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2050 || all params: 335143938 || trainable%: 0.0006\n"
     ]
    }
   ],
   "source": [
    "trainable_params = 0\n",
    "all_params = 0\n",
    "\n",
    "for param in model_sft.parameters():\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "    all_params += param.numel()\n",
    "\n",
    "print(f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predict):\n",
    "    preds, labels = eval_predict\n",
    "    preds = preds.argmax(axis=-1)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_train = TrainingArguments(\n",
    "    output_dir=os.path.join(path_output, \"model_sft\"),\n",
    "    num_train_epochs=config_model.get(\"epochs\"),\n",
    "    per_device_train_batch_size=config_model.get(\"batch_size\"),\n",
    "    per_device_eval_batch_size=config_model.get(\"batch_size\"),\n",
    "    gradient_accumulation_steps=config_model.get(\"gradient_steps\"),\n",
    "    gradient_checkpointing=True, \n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=config_model.get(\"learning_rate\"),\n",
    "    weight_decay=config_model.get(\"weight_decay\"),\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_sft,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args_train,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=dataset_train_tokenized,\n",
    "    eval_dataset=dataset_test_tokenized,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06022858500e43d3a0ed47f3d991226a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1506, 'grad_norm': 4.360788345336914, 'learning_rate': 0.009000000000000001, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d36a0adf5894a738ebf434c155af785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9693963527679443, 'eval_f1': 0.015384615384615384, 'eval_runtime': 2.1395, 'eval_samples_per_second': 103.298, 'eval_steps_per_second': 1.87, 'epoch': 1.0}\n",
      "{'loss': 2.3663, 'grad_norm': 24.328449249267578, 'learning_rate': 0.008, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ca23d25c54ae6b3a3b2876319f708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7942917943000793, 'eval_f1': 0.7335243553008596, 'eval_runtime': 2.1391, 'eval_samples_per_second': 103.314, 'eval_steps_per_second': 1.87, 'epoch': 2.0}\n",
      "{'loss': 1.0314, 'grad_norm': 3.5117805004119873, 'learning_rate': 0.006999999999999999, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc785268dbbf424d95509978b0d8fffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6912957429885864, 'eval_f1': 0.7335243553008596, 'eval_runtime': 2.1641, 'eval_samples_per_second': 102.119, 'eval_steps_per_second': 1.848, 'epoch': 3.0}\n",
      "{'loss': 1.6823, 'grad_norm': 11.935359954833984, 'learning_rate': 0.006, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756f841fc66c4ea6a770af737a2cde9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.703606367111206, 'eval_f1': 0.1875, 'eval_runtime': 2.1464, 'eval_samples_per_second': 102.963, 'eval_steps_per_second': 1.864, 'epoch': 4.0}\n",
      "{'loss': 1.0164, 'grad_norm': 18.509540557861328, 'learning_rate': 0.005, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f79441b416f424b8cff031e4f22e580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6919796466827393, 'eval_f1': 0.7371428571428571, 'eval_runtime': 2.1584, 'eval_samples_per_second': 102.392, 'eval_steps_per_second': 1.853, 'epoch': 5.0}\n",
      "{'loss': 1.413, 'grad_norm': 22.21833610534668, 'learning_rate': 0.004, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb363d40ca404fe4af996c6da6130e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2213325500488281, 'eval_f1': 0.015384615384615384, 'eval_runtime': 2.1858, 'eval_samples_per_second': 101.105, 'eval_steps_per_second': 1.83, 'epoch': 6.0}\n",
      "{'loss': 1.0191, 'grad_norm': 7.280005931854248, 'learning_rate': 0.003, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d024f217f7547aca2c85dee93ed3013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.144714117050171, 'eval_f1': 0.7335243553008596, 'eval_runtime': 2.0962, 'eval_samples_per_second': 105.43, 'eval_steps_per_second': 1.908, 'epoch': 7.0}\n",
      "{'loss': 0.8856, 'grad_norm': 7.667726039886475, 'learning_rate': 0.002, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7017c7d6ea864cdda280f87e4867840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7121362686157227, 'eval_f1': 0.1232876712328767, 'eval_runtime': 2.0603, 'eval_samples_per_second': 107.265, 'eval_steps_per_second': 1.941, 'epoch': 8.0}\n",
      "{'loss': 0.7652, 'grad_norm': 3.4028127193450928, 'learning_rate': 0.001, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d10b8477d4a35918bf08b7ff710a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.684851884841919, 'eval_f1': 0.7371428571428571, 'eval_runtime': 2.1015, 'eval_samples_per_second': 105.162, 'eval_steps_per_second': 1.903, 'epoch': 9.0}\n",
      "{'loss': 0.6987, 'grad_norm': 4.860345363616943, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8b75ba736b43f8ba9d752ec06c6bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6815494894981384, 'eval_f1': 0.7371428571428571, 'eval_runtime': 2.1235, 'eval_samples_per_second': 104.072, 'eval_steps_per_second': 1.884, 'epoch': 10.0}\n",
      "{'train_runtime': 119.7151, 'train_samples_per_second': 73.758, 'train_steps_per_second': 1.169, 'train_loss': 1.3028578553880965, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "res_train = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-8: 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Missouri lawmakers are considering a boycott of companies that boycott Israel.\"\n",
    "sent2 = \"Missouri lawmakers are considering a government boycott of companies that boycott Israel.\"\n",
    "sents = [(sent1, sent2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sent1, sent2, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "# inputs = tokenizer(sents, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3943, 0.6057]], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_sft.eval()\n",
    "with th.inference_mode():\n",
    "    out_mlp = model_sft(**inputs)\n",
    "    y_hat = th.softmax(out_mlp.logits, dim=1)\n",
    "    y_pred = th.argmax(y_hat, dim=1)\n",
    "\n",
    "print(y_hat)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
