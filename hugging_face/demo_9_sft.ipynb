{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U datasets accelerate peft trl tensorboard bitsandbytes langchain sentencepiece transformers\n",
    "# !pip install transformers==4.37.2 --user\n",
    "# !pip install tiktoken einops transformers_stream_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets import (load_dataset, load_from_disk, Dataset)\n",
    "from transformers import (AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig,\n",
    "                          TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForSeq2Seq, DataCollatorForTokenClassification)\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from peft import (LoraConfig, get_peft_model, PeftModel, TaskType, prepare_model_for_kbit_training)\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda; devive_cnt = 1\n",
      "2.0.1+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "devive_cnt = th.cuda.device_count()\n",
    "print(f\"device = {device}; devive_cnt = {devive_cnt}\")\n",
    "print(th.__version__)\n",
    "print(th.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/gemini/code\"\n",
    "path_data = os.path.join(os.path.dirname(path_project), \"data-1\")\n",
    "path_model = os.path.join(os.path.dirname(path_project), \"pretrain\")\n",
    "path_output = os.path.join(os.path.dirname(path_project), \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-1: 载入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train-00000-of-00001-a09b74b3ef9c3b56.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 52002 examples [00:00, 131581.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    path=\"parquet\",\n",
    "    data_files=os.path.join(path_data, filename),\n",
    "    split=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(2000))\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=0) \n",
    "dataset_train, dataset_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-2: tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"chatglm3-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=path_model,\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    # pad_token='<|extra_0|>',  # qwen\n",
    "    # eos_token='<|endoftext|>',  # qwen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token  # '<unk>'\n",
    "# tokenizer.eos_token  # '</s>'\n",
    "# tokenizer.pad_token = tokenizer.eos_token  # 半精度训练时需要\n",
    "# tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n",
    "# tokenizer.padding_side\n",
    "# tokenizer.padding_side = \"right\"  # llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-3: 配置量化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bnb = BitsAndBytesConfig(\n",
    "    # load_in_8bit=True,\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=th.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-4: 载入基础/任务大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [03:12<00:00, 27.43s/it]\n"
     ]
    }
   ],
   "source": [
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=path_model,\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=th.float16,\n",
    "    # quantization_config=config_bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注：glm3 没有了 lm_head，有一个 output_layer，这个时候可能会分配到两个 device，导致计算 loss 的时候报错\n",
    "if th.cuda.device_count() > 1:\n",
    "\tmodel_base.hf_device_map[\"transformer.output_layer\"] = model_base.hf_device_map[\"transformer.embedding\"]  # 1 <- 0\n",
    "\tdct_device_map = model_base.hf_device_map\n",
    " \n",
    "\tmodel_base.cpu()\n",
    "\tdel model_base\n",
    "\tth.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已分配的GPU内存：0.00G, 已缓存的GPU内存：0.00G\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = th.cuda.memory_allocated()\n",
    "cached_memory = th.cuda.memory_cached()\n",
    "print(f\"已分配的GPU内存：{allocated_memory / 1024**3:.2f}G, 已缓存的GPU内存：{cached_memory / 1024**3:.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [02:49<00:00, 24.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# re-load\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=path_model,\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=dct_device_map,\n",
    "    torch_dtype=th.float16,\n",
    "    # quantization_config=config_bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    }
   ],
   "source": [
    "# note: use gradient checkpointing to save memory at the expense of slower backward pass.\n",
    "model_base.gradient_checkpointing_enable()  # if TrainingArguments(gradient_checkpointing=True)\n",
    "# note: Enables the gradients for the input embeddings. This is useful for fine-tuning adapter weights while keeping the model weights fixed. \n",
    "model_base.enable_input_require_grads()  # if TrainingArguments(gradient_checkpointing=True)\n",
    "model_base.config.use_cache = False\n",
    "\n",
    "if th.cuda.device_count() > 1:\n",
    "    model_base.is_parallelizable = True\n",
    "    model_base.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  name: transformer.embedding.word_embeddings.weight;  shape: torch.Size([65024, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "1  name: transformer.encoder.layers.0.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "2  name: transformer.encoder.layers.0.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "3  name: transformer.encoder.layers.0.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "4  name: transformer.encoder.layers.0.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "5  name: transformer.encoder.layers.0.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "6  name: transformer.encoder.layers.0.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "7  name: transformer.encoder.layers.0.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "8  name: transformer.encoder.layers.1.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "9  name: transformer.encoder.layers.1.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "10  name: transformer.encoder.layers.1.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "11  name: transformer.encoder.layers.1.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "12  name: transformer.encoder.layers.1.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "13  name: transformer.encoder.layers.1.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "14  name: transformer.encoder.layers.1.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "15  name: transformer.encoder.layers.2.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "16  name: transformer.encoder.layers.2.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "17  name: transformer.encoder.layers.2.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "18  name: transformer.encoder.layers.2.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "19  name: transformer.encoder.layers.2.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "20  name: transformer.encoder.layers.2.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "21  name: transformer.encoder.layers.2.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "22  name: transformer.encoder.layers.3.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "23  name: transformer.encoder.layers.3.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "24  name: transformer.encoder.layers.3.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "25  name: transformer.encoder.layers.3.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "26  name: transformer.encoder.layers.3.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "27  name: transformer.encoder.layers.3.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "28  name: transformer.encoder.layers.3.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "29  name: transformer.encoder.layers.4.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "30  name: transformer.encoder.layers.4.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "31  name: transformer.encoder.layers.4.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "32  name: transformer.encoder.layers.4.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "33  name: transformer.encoder.layers.4.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "34  name: transformer.encoder.layers.4.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "35  name: transformer.encoder.layers.4.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "36  name: transformer.encoder.layers.5.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "37  name: transformer.encoder.layers.5.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "38  name: transformer.encoder.layers.5.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "39  name: transformer.encoder.layers.5.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "40  name: transformer.encoder.layers.5.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "41  name: transformer.encoder.layers.5.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "42  name: transformer.encoder.layers.5.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "43  name: transformer.encoder.layers.6.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "44  name: transformer.encoder.layers.6.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "45  name: transformer.encoder.layers.6.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "46  name: transformer.encoder.layers.6.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "47  name: transformer.encoder.layers.6.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "48  name: transformer.encoder.layers.6.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "49  name: transformer.encoder.layers.6.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "50  name: transformer.encoder.layers.7.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "51  name: transformer.encoder.layers.7.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "52  name: transformer.encoder.layers.7.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "53  name: transformer.encoder.layers.7.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "54  name: transformer.encoder.layers.7.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "55  name: transformer.encoder.layers.7.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "56  name: transformer.encoder.layers.7.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "57  name: transformer.encoder.layers.8.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "58  name: transformer.encoder.layers.8.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "59  name: transformer.encoder.layers.8.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "60  name: transformer.encoder.layers.8.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "61  name: transformer.encoder.layers.8.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "62  name: transformer.encoder.layers.8.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "63  name: transformer.encoder.layers.8.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "64  name: transformer.encoder.layers.9.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "65  name: transformer.encoder.layers.9.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "66  name: transformer.encoder.layers.9.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "67  name: transformer.encoder.layers.9.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "68  name: transformer.encoder.layers.9.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "69  name: transformer.encoder.layers.9.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "70  name: transformer.encoder.layers.9.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "71  name: transformer.encoder.layers.10.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "72  name: transformer.encoder.layers.10.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "73  name: transformer.encoder.layers.10.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "74  name: transformer.encoder.layers.10.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "75  name: transformer.encoder.layers.10.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "76  name: transformer.encoder.layers.10.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "77  name: transformer.encoder.layers.10.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "78  name: transformer.encoder.layers.11.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "79  name: transformer.encoder.layers.11.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "80  name: transformer.encoder.layers.11.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "81  name: transformer.encoder.layers.11.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "82  name: transformer.encoder.layers.11.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "83  name: transformer.encoder.layers.11.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "84  name: transformer.encoder.layers.11.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "85  name: transformer.encoder.layers.12.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "86  name: transformer.encoder.layers.12.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "87  name: transformer.encoder.layers.12.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:0\n",
      "88  name: transformer.encoder.layers.12.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "89  name: transformer.encoder.layers.12.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:0\n",
      "90  name: transformer.encoder.layers.12.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:0\n",
      "91  name: transformer.encoder.layers.12.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:0\n",
      "92  name: transformer.encoder.layers.13.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "93  name: transformer.encoder.layers.13.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "94  name: transformer.encoder.layers.13.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "95  name: transformer.encoder.layers.13.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "96  name: transformer.encoder.layers.13.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "97  name: transformer.encoder.layers.13.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "98  name: transformer.encoder.layers.13.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "99  name: transformer.encoder.layers.14.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "100  name: transformer.encoder.layers.14.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "101  name: transformer.encoder.layers.14.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "102  name: transformer.encoder.layers.14.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "103  name: transformer.encoder.layers.14.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "104  name: transformer.encoder.layers.14.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "105  name: transformer.encoder.layers.14.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "106  name: transformer.encoder.layers.15.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "107  name: transformer.encoder.layers.15.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "108  name: transformer.encoder.layers.15.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "109  name: transformer.encoder.layers.15.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "110  name: transformer.encoder.layers.15.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "111  name: transformer.encoder.layers.15.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "112  name: transformer.encoder.layers.15.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "113  name: transformer.encoder.layers.16.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "114  name: transformer.encoder.layers.16.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "115  name: transformer.encoder.layers.16.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "116  name: transformer.encoder.layers.16.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "117  name: transformer.encoder.layers.16.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "118  name: transformer.encoder.layers.16.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "119  name: transformer.encoder.layers.16.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "120  name: transformer.encoder.layers.17.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "121  name: transformer.encoder.layers.17.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "122  name: transformer.encoder.layers.17.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "123  name: transformer.encoder.layers.17.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "124  name: transformer.encoder.layers.17.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "125  name: transformer.encoder.layers.17.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "126  name: transformer.encoder.layers.17.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "127  name: transformer.encoder.layers.18.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "128  name: transformer.encoder.layers.18.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "129  name: transformer.encoder.layers.18.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "130  name: transformer.encoder.layers.18.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "131  name: transformer.encoder.layers.18.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "132  name: transformer.encoder.layers.18.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "133  name: transformer.encoder.layers.18.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "134  name: transformer.encoder.layers.19.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "135  name: transformer.encoder.layers.19.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "136  name: transformer.encoder.layers.19.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "137  name: transformer.encoder.layers.19.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "138  name: transformer.encoder.layers.19.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "139  name: transformer.encoder.layers.19.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "140  name: transformer.encoder.layers.19.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "141  name: transformer.encoder.layers.20.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "142  name: transformer.encoder.layers.20.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "143  name: transformer.encoder.layers.20.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "144  name: transformer.encoder.layers.20.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "145  name: transformer.encoder.layers.20.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "146  name: transformer.encoder.layers.20.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "147  name: transformer.encoder.layers.20.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "148  name: transformer.encoder.layers.21.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "149  name: transformer.encoder.layers.21.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "150  name: transformer.encoder.layers.21.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "151  name: transformer.encoder.layers.21.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "152  name: transformer.encoder.layers.21.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "153  name: transformer.encoder.layers.21.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "154  name: transformer.encoder.layers.21.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "155  name: transformer.encoder.layers.22.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "156  name: transformer.encoder.layers.22.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "157  name: transformer.encoder.layers.22.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "158  name: transformer.encoder.layers.22.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "159  name: transformer.encoder.layers.22.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "160  name: transformer.encoder.layers.22.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "161  name: transformer.encoder.layers.22.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "162  name: transformer.encoder.layers.23.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "163  name: transformer.encoder.layers.23.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "164  name: transformer.encoder.layers.23.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "165  name: transformer.encoder.layers.23.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "166  name: transformer.encoder.layers.23.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "167  name: transformer.encoder.layers.23.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "168  name: transformer.encoder.layers.23.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "169  name: transformer.encoder.layers.24.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "170  name: transformer.encoder.layers.24.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "171  name: transformer.encoder.layers.24.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "172  name: transformer.encoder.layers.24.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "173  name: transformer.encoder.layers.24.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "174  name: transformer.encoder.layers.24.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "175  name: transformer.encoder.layers.24.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "176  name: transformer.encoder.layers.25.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "177  name: transformer.encoder.layers.25.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "178  name: transformer.encoder.layers.25.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "179  name: transformer.encoder.layers.25.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "180  name: transformer.encoder.layers.25.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "181  name: transformer.encoder.layers.25.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "182  name: transformer.encoder.layers.25.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "183  name: transformer.encoder.layers.26.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "184  name: transformer.encoder.layers.26.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "185  name: transformer.encoder.layers.26.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "186  name: transformer.encoder.layers.26.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "187  name: transformer.encoder.layers.26.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "188  name: transformer.encoder.layers.26.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "189  name: transformer.encoder.layers.26.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "190  name: transformer.encoder.layers.27.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "191  name: transformer.encoder.layers.27.self_attention.query_key_value.weight;  shape: torch.Size([4608, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "192  name: transformer.encoder.layers.27.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.float16;  device: cuda:1\n",
      "193  name: transformer.encoder.layers.27.self_attention.dense.weight;  shape: torch.Size([4096, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "194  name: transformer.encoder.layers.27.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "195  name: transformer.encoder.layers.27.mlp.dense_h_to_4h.weight;  shape: torch.Size([27392, 4096]);  dtype: torch.float16;  device: cuda:1\n",
      "196  name: transformer.encoder.layers.27.mlp.dense_4h_to_h.weight;  shape: torch.Size([4096, 13696]);  dtype: torch.float16;  device: cuda:1\n",
      "197  name: transformer.encoder.final_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.float16;  device: cuda:1\n",
      "198  name: transformer.output_layer.weight;  shape: torch.Size([65024, 4096]);  dtype: torch.float16;  device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for i, (name, parm) in enumerate(model_base.named_parameters()):\n",
    "    print(f\"{i}  name: {name};  shape: {parm.shape};  dtype: {parm.dtype};  device: {parm.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(model_base.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已分配的GPU内存：5.94G, 已缓存的GPU内存：5.95G\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = th.cuda.memory_allocated()\n",
    "cached_memory = th.cuda.memory_cached()\n",
    "print(f\"已分配的GPU内存：{allocated_memory / 1024**3:.2f}G, 已缓存的GPU内存：{cached_memory / 1024**3:.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check embedding_size\n",
    "embedding_size = model_base.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model_base.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-5: 配置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = {\n",
    "    \"rank\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"use_rslora\": True,\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 8,\n",
    "    \"gradient_steps\": 1,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_seq_lenght\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-6: 配置LoRA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA: Low-Rank Adaptation of Large Language Models\n",
    "# config_lora = LoraConfig(target_modules=[\"0\"])\n",
    "# config_lora = LoraConfig(target_modules=[\"query_key_value\", \"dense_4h_to_h\"])\n",
    "# config_lora = LoraConfig(target_modules=[\".*\\.1.*query_key_value\"])\n",
    "# config_lora = LoraConfig(target_modules=[\"query_key_value\"], modules_to_save=[\"word_embeddings\"])\n",
    "config_lora = LoraConfig(\n",
    "    r=config_model.get(\"rank\"),\n",
    "    lora_alpha=config_model.get(\"lora_alpha\"),\n",
    "    lora_dropout=config_model.get(\"lora_dropout\"),\n",
    "    use_rslora=config_model.get(\"use_rslora\"),\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_base = prepare_model_for_kbit_training(model_base)\n",
    "model_lora = get_peft_model(model=model_base, peft_config=config_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print_trainable_parameters - 1\n",
    "print(model_lora.print_trainable_parameters())\n",
    "\n",
    "# print_trainable_parameters - 2\n",
    "# trainable_params = 0\n",
    "# all_params = 0\n",
    "\n",
    "# for param in model_lora.parameters():\n",
    "#     if param.requires_grad:\n",
    "#         trainable_params += param.numel()\n",
    "#     all_params += param.numel()\n",
    "\n",
    "# print(f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-7: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_train = TrainingArguments(\n",
    "    output_dir=os.path.join(path_output, \"model_sft\"),\n",
    "    num_train_epochs=config_model.get(\"epochs\"),\n",
    "    per_device_train_batch_size=config_model.get(\"batch_size\"),\n",
    "    per_device_eval_batch_size=config_model.get(\"batch_size\"),\n",
    "    gradient_accumulation_steps=config_model.get(\"gradient_steps\"),\n",
    "    gradient_checkpointing=True, \n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=config_model.get(\"learning_rate\"),\n",
    "    weight_decay=config_model.get(\"weight_decay\"),\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    #metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorForLanguageModeling(tokenizer, mlm=False) \n",
    "# collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "# collate_fn = DataCollatorForSeq2Seq(tokenizer, padding=True)\n",
    "# collate_fn = DataCollatorForTokenClassification(tokenizer)\n",
    "# writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 180 examples [00:01, 149.07 examples/s]\n",
      "Generating train split: 45 examples [00:00, 147.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model_lora,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args_train,\n",
    "    peft_config=config_lora,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    dataset_text_field=\"text\", \n",
    "    packing=True,\n",
    "    max_seq_length=config_model.get(\"max_seq_length\"),\n",
    "    #compute_metrics=compute_metrics,\n",
    "    # callbacks=[TensorBoardCallback(writer)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-8: 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d80198c7bc441f9a48dfd4cf5b8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.78125,\n",
       " 'eval_runtime': 11.3416,\n",
       " 'eval_samples_per_second': 0.353,\n",
       " 'eval_steps_per_second': 0.088,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_eval = trainer.evaluate()\n",
    "# res_eval = trainer.evaluate(dataset_train)\n",
    "# res_eval = trainer.evaluate(dataset_test)\n",
    "res_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-9: 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=os.path.join(path_model, \"model_sft\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-10: 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已分配的GPU内存：5.97G, 已缓存的GPU内存：6.26G\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = th.cuda.memory_allocated()\n",
    "cached_memory = th.cuda.memory_cached()\n",
    "print(f\"已分配的GPU内存：{allocated_memory / 1024**3:.2f}G, 已缓存的GPU内存：{cached_memory / 1024**3:.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 释放不再使用的GPU内存\n",
    "model_base.cpu()\n",
    "del model_base\n",
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model_base\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=th.bfloat16,\n",
    "    quantization_config=config_bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = prepare_model_for_kbit_training(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model_sft\n",
    "model_sft = PeftModel.from_pretrained(\n",
    "    model=model_base,\n",
    "    model_id=os.path.join(path_model, \"model_sft\"),\n",
    "    is_trainable=False\n",
    ")\n",
    "model_sft = model_sft.merge_and_unload()  # W + BA, speed up, but errors when use 8-bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sft.save_pretrained(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-11: 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Design a database to record employee salaries.\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "response, history = model_sft.chat(tokenizer, query=query, history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To design a database to record employee salaries, we will need to create a table with the following columns:\n",
      "\n",
      "1.  Employee ID (Primary Key)\n",
      "2.  First Name\n",
      "3.  Last Name\n",
      "4.  Salary\n",
      "5.  Hire Date\n",
      "\n",
      "The Employee ID will serve as the primary key for the table, ensuring that each employee has a unique record. The First Name and Last Name columns will store the employee's full name, and the Salary column will store the employee's salary information. The Hire Date column will store the date the employee was hired.\n",
      "\n",
      "We can also add additional columns to the table if necessary, such as an End Date column to track the date the employee left the company, a Department column to specify the employee's department, or an Employee Title column to indicate the employee's job title.\n",
      "\n",
      "Once the table is created, we can use SQL queries to retrieve specific information from the database, such as the total salary of all employees in a particular department or the salary of an employee with a specific employee ID.\n",
      "\n",
      "In summary, designing a database to record employee salaries involves creating a table with columns that store employee information and using SQL queries to retrieve specific information from the database.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
