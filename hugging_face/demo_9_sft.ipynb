{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U datasets accelerate peft trl tensorboard bitsandbytes langchain sentencepiece --user\n",
    "# %pip install transformers==4.37.2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from datasets import (load_dataset, load_from_disk, Dataset)\n",
    "from transformers import (AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig,\n",
    "                          TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForSeq2Seq, DataCollatorForTokenClassification)\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from peft import (LoraConfig, get_peft_model, PeftModel, TaskType)\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"C:/my_project/MyGit/Machine-Learning-Column/hugging_face\"\n",
    "path_data = os.path.join(os.path.dirname(path_project), \"data\")\n",
    "path_model = os.path.join(os.path.dirname(path_project), \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-1: 载入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"NousResearch/json-mode-eval/train-00000-of-00001.parquet\"\n",
    "filename = \"tatsu-lab/alpaca/train-00000-of-00001-a09b74b3ef9c3b56.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    path=\"parquet\",\n",
    "    data_files=os.path.join(path_data, filename),\n",
    "    split=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(200))\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=0) \n",
    "dataset_train, dataset_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-2: tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"chatglm3-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token  # '<unk>'\n",
    "# tokenizer.eos_token  # '</s>'\n",
    "# tokenizer.pad_token = tokenizer.eos_token  # 半精度训练时需要\n",
    "# tokenizer.padding_side = \"right\"  # llama2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-3: 配置量化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bnb = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    # load_in_4bit=True,\n",
    "    # bnb_4bit_quant_type=\"nf4\",\n",
    "    # bnb_4bit_compute_dtype=th.bfloat16,\n",
    "    # bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-4: 载入基础/任务大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf9b28b61664b368dea8ab83e4e2a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Files\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=th.bfloat16,\n",
    "    quantization_config=config_bnb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  name: transformer.embedding.word_embeddings.weight;  shape: torch.Size([65024, 4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "1  name: transformer.encoder.layers.0.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "2  name: transformer.encoder.layers.0.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "3  name: transformer.encoder.layers.0.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "4  name: transformer.encoder.layers.0.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "5  name: transformer.encoder.layers.0.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "6  name: transformer.encoder.layers.0.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "7  name: transformer.encoder.layers.0.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "8  name: transformer.encoder.layers.1.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "9  name: transformer.encoder.layers.1.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "10  name: transformer.encoder.layers.1.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "11  name: transformer.encoder.layers.1.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "12  name: transformer.encoder.layers.1.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "13  name: transformer.encoder.layers.1.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "14  name: transformer.encoder.layers.1.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "15  name: transformer.encoder.layers.2.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "16  name: transformer.encoder.layers.2.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "17  name: transformer.encoder.layers.2.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "18  name: transformer.encoder.layers.2.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "19  name: transformer.encoder.layers.2.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "20  name: transformer.encoder.layers.2.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "21  name: transformer.encoder.layers.2.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "22  name: transformer.encoder.layers.3.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "23  name: transformer.encoder.layers.3.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "24  name: transformer.encoder.layers.3.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "25  name: transformer.encoder.layers.3.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "26  name: transformer.encoder.layers.3.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "27  name: transformer.encoder.layers.3.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "28  name: transformer.encoder.layers.3.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "29  name: transformer.encoder.layers.4.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "30  name: transformer.encoder.layers.4.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "31  name: transformer.encoder.layers.4.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "32  name: transformer.encoder.layers.4.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "33  name: transformer.encoder.layers.4.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "34  name: transformer.encoder.layers.4.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "35  name: transformer.encoder.layers.4.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "36  name: transformer.encoder.layers.5.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "37  name: transformer.encoder.layers.5.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "38  name: transformer.encoder.layers.5.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "39  name: transformer.encoder.layers.5.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "40  name: transformer.encoder.layers.5.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "41  name: transformer.encoder.layers.5.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "42  name: transformer.encoder.layers.5.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "43  name: transformer.encoder.layers.6.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "44  name: transformer.encoder.layers.6.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "45  name: transformer.encoder.layers.6.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "46  name: transformer.encoder.layers.6.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "47  name: transformer.encoder.layers.6.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "48  name: transformer.encoder.layers.6.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "49  name: transformer.encoder.layers.6.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "50  name: transformer.encoder.layers.7.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "51  name: transformer.encoder.layers.7.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "52  name: transformer.encoder.layers.7.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "53  name: transformer.encoder.layers.7.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "54  name: transformer.encoder.layers.7.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "55  name: transformer.encoder.layers.7.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "56  name: transformer.encoder.layers.7.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "57  name: transformer.encoder.layers.8.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "58  name: transformer.encoder.layers.8.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "59  name: transformer.encoder.layers.8.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "60  name: transformer.encoder.layers.8.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "61  name: transformer.encoder.layers.8.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "62  name: transformer.encoder.layers.8.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "63  name: transformer.encoder.layers.8.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "64  name: transformer.encoder.layers.9.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "65  name: transformer.encoder.layers.9.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "66  name: transformer.encoder.layers.9.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "67  name: transformer.encoder.layers.9.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "68  name: transformer.encoder.layers.9.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "69  name: transformer.encoder.layers.9.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "70  name: transformer.encoder.layers.9.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "71  name: transformer.encoder.layers.10.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "72  name: transformer.encoder.layers.10.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "73  name: transformer.encoder.layers.10.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "74  name: transformer.encoder.layers.10.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "75  name: transformer.encoder.layers.10.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "76  name: transformer.encoder.layers.10.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "77  name: transformer.encoder.layers.10.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "78  name: transformer.encoder.layers.11.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "79  name: transformer.encoder.layers.11.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "80  name: transformer.encoder.layers.11.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "81  name: transformer.encoder.layers.11.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "82  name: transformer.encoder.layers.11.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "83  name: transformer.encoder.layers.11.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "84  name: transformer.encoder.layers.11.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "85  name: transformer.encoder.layers.12.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "86  name: transformer.encoder.layers.12.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "87  name: transformer.encoder.layers.12.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "88  name: transformer.encoder.layers.12.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "89  name: transformer.encoder.layers.12.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "90  name: transformer.encoder.layers.12.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "91  name: transformer.encoder.layers.12.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "92  name: transformer.encoder.layers.13.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "93  name: transformer.encoder.layers.13.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "94  name: transformer.encoder.layers.13.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "95  name: transformer.encoder.layers.13.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "96  name: transformer.encoder.layers.13.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "97  name: transformer.encoder.layers.13.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "98  name: transformer.encoder.layers.13.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "99  name: transformer.encoder.layers.14.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "100  name: transformer.encoder.layers.14.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "101  name: transformer.encoder.layers.14.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "102  name: transformer.encoder.layers.14.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "103  name: transformer.encoder.layers.14.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "104  name: transformer.encoder.layers.14.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "105  name: transformer.encoder.layers.14.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "106  name: transformer.encoder.layers.15.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "107  name: transformer.encoder.layers.15.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "108  name: transformer.encoder.layers.15.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "109  name: transformer.encoder.layers.15.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "110  name: transformer.encoder.layers.15.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "111  name: transformer.encoder.layers.15.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "112  name: transformer.encoder.layers.15.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "113  name: transformer.encoder.layers.16.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "114  name: transformer.encoder.layers.16.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "115  name: transformer.encoder.layers.16.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "116  name: transformer.encoder.layers.16.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "117  name: transformer.encoder.layers.16.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "118  name: transformer.encoder.layers.16.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "119  name: transformer.encoder.layers.16.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "120  name: transformer.encoder.layers.17.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "121  name: transformer.encoder.layers.17.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "122  name: transformer.encoder.layers.17.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "123  name: transformer.encoder.layers.17.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "124  name: transformer.encoder.layers.17.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "125  name: transformer.encoder.layers.17.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "126  name: transformer.encoder.layers.17.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "127  name: transformer.encoder.layers.18.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "128  name: transformer.encoder.layers.18.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "129  name: transformer.encoder.layers.18.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "130  name: transformer.encoder.layers.18.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "131  name: transformer.encoder.layers.18.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "132  name: transformer.encoder.layers.18.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "133  name: transformer.encoder.layers.18.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "134  name: transformer.encoder.layers.19.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "135  name: transformer.encoder.layers.19.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "136  name: transformer.encoder.layers.19.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "137  name: transformer.encoder.layers.19.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "138  name: transformer.encoder.layers.19.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "139  name: transformer.encoder.layers.19.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "140  name: transformer.encoder.layers.19.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "141  name: transformer.encoder.layers.20.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "142  name: transformer.encoder.layers.20.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "143  name: transformer.encoder.layers.20.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "144  name: transformer.encoder.layers.20.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "145  name: transformer.encoder.layers.20.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "146  name: transformer.encoder.layers.20.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "147  name: transformer.encoder.layers.20.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "148  name: transformer.encoder.layers.21.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "149  name: transformer.encoder.layers.21.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "150  name: transformer.encoder.layers.21.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "151  name: transformer.encoder.layers.21.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "152  name: transformer.encoder.layers.21.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "153  name: transformer.encoder.layers.21.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "154  name: transformer.encoder.layers.21.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "155  name: transformer.encoder.layers.22.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "156  name: transformer.encoder.layers.22.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "157  name: transformer.encoder.layers.22.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "158  name: transformer.encoder.layers.22.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "159  name: transformer.encoder.layers.22.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "160  name: transformer.encoder.layers.22.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "161  name: transformer.encoder.layers.22.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "162  name: transformer.encoder.layers.23.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "163  name: transformer.encoder.layers.23.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "164  name: transformer.encoder.layers.23.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "165  name: transformer.encoder.layers.23.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "166  name: transformer.encoder.layers.23.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "167  name: transformer.encoder.layers.23.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "168  name: transformer.encoder.layers.23.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "169  name: transformer.encoder.layers.24.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "170  name: transformer.encoder.layers.24.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "171  name: transformer.encoder.layers.24.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "172  name: transformer.encoder.layers.24.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "173  name: transformer.encoder.layers.24.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "174  name: transformer.encoder.layers.24.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "175  name: transformer.encoder.layers.24.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "176  name: transformer.encoder.layers.25.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "177  name: transformer.encoder.layers.25.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "178  name: transformer.encoder.layers.25.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "179  name: transformer.encoder.layers.25.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "180  name: transformer.encoder.layers.25.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "181  name: transformer.encoder.layers.25.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "182  name: transformer.encoder.layers.25.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "183  name: transformer.encoder.layers.26.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "184  name: transformer.encoder.layers.26.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "185  name: transformer.encoder.layers.26.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "186  name: transformer.encoder.layers.26.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "187  name: transformer.encoder.layers.26.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "188  name: transformer.encoder.layers.26.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "189  name: transformer.encoder.layers.26.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "190  name: transformer.encoder.layers.27.input_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "191  name: transformer.encoder.layers.27.self_attention.query_key_value.weight;  shape: torch.Size([9437184, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "192  name: transformer.encoder.layers.27.self_attention.query_key_value.bias;  shape: torch.Size([4608]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "193  name: transformer.encoder.layers.27.self_attention.dense.weight;  shape: torch.Size([8388608, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "194  name: transformer.encoder.layers.27.post_attention_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "195  name: transformer.encoder.layers.27.mlp.dense_h_to_4h.weight;  shape: torch.Size([56098816, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "196  name: transformer.encoder.layers.27.mlp.dense_4h_to_h.weight;  shape: torch.Size([28049408, 1]);  dtype: torch.uint8;  device: cuda:0\n",
      "197  name: transformer.encoder.final_layernorm.weight;  shape: torch.Size([4096]);  dtype: torch.bfloat16;  device: cuda:0\n",
      "198  name: transformer.output_layer.weight;  shape: torch.Size([65024, 4096]);  dtype: torch.bfloat16;  device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for i, (name, parm) in enumerate(model_base.named_parameters()):\n",
    "    print(f\"{i}  name: {name};  shape: {parm.shape};  dtype: {parm.dtype};  device: {parm.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(model_base.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check embedding_size\n",
    "embedding_size = model_base.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model_base.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-5: 配置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_model = {\n",
    "    \"rank\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"use_rslora\": True,\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 2,\n",
    "    \"gradient_steps\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_seq_lenght\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-6: 配置LoRA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA: Low-Rank Adaptation of Large Language Models\n",
    "# config_lora = LoraConfig(target_modules=[\"0\"])\n",
    "# config_lora = LoraConfig(target_modules=[\"query_key_value\", \"dense_4h_to_h\"])\n",
    "# config_lora = LoraConfig(target_modules=[\".*\\.1.*query_key_value\"])\n",
    "# config_lora = LoraConfig(target_modules=[\"query_key_value\"], modules_to_save=[\"word_embeddings\"])\n",
    "config_lora = LoraConfig(\n",
    "    r=config_model.get(\"rank\"),\n",
    "    lora_alpha=config_model.get(\"lora_alpha\"),\n",
    "    lora_dropout=config_model.get(\"lora_dropout\"),\n",
    "    use_rslora=config_model.get(\"use_rslora\"),\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_base = prepare_model_for_int8_training(model_base)\n",
    "model_lora = get_peft_model(model=model_base, peft_config=config_lora)\n",
    "# model_lora.enable_input_require_grads()  # if TrainingArguments(gradient_checkpointing=True)\n",
    "model_lora.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1949696 || all params: 3390261248 || trainable%: 0.0575\n"
     ]
    }
   ],
   "source": [
    "# print_trainable_parameters - 1\n",
    "print(model_lora.print_trainable_parameters())\n",
    "\n",
    "# print_trainable_parameters - 2\n",
    "# trainable_params = 0\n",
    "# all_params = 0\n",
    "\n",
    "# for param in model_lora.parameters():\n",
    "#     if param.requires_grad:\n",
    "#         trainable_params += param.numel()\n",
    "#     all_params += param.numel()\n",
    "\n",
    "# print(f\"trainable params: {trainable_params} || all params: {all_params} || trainable%: {100 * trainable_params / all_params:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-7: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_train = TrainingArguments(\n",
    "    output_dir=os.path.join(path_model, \"model_sft\"),\n",
    "    num_train_epochs=config_model.get(\"epochs\"),\n",
    "    per_device_train_batch_size=config_model.get(\"batch_size\"),\n",
    "    per_device_eval_batch_size=config_model.get(\"batch_size\"),\n",
    "    gradient_accumulation_steps=config_model.get(\"gradient_steps\"),\n",
    "    gradient_checkpointing=True, \n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=config_model.get(\"learning_rate\"),\n",
    "    weight_decay=config_model.get(\"weight_decay\"),\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    #metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorForLanguageModeling(tokenizer, mlm=False) \n",
    "# collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "# collate_fn = DataCollatorForSeq2Seq(tokenizer, padding=True)\n",
    "# collate_fn = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Roaming\\Python\\Python311\\site-packages\\trl\\trainer\\sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukas\\AppData\\Roaming\\Python\\Python311\\site-packages\\trl\\trainer\\sft_trainer.py:317: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lukas\\AppData\\Roaming\\Python\\Python311\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model_lora,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args_train,\n",
    "    peft_config=config_lora,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    dataset_text_field=\"text\", \n",
    "    packing=True,\n",
    "    max_seq_length=config_model.get(\"max_seq_length\"),\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-8: 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eval = trainer.evaluate()\n",
    "# res_eval = trainer.evaluate(dataset_train)\n",
    "# res_eval = trainer.evaluate(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-9: 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=os.path.join(path_model, \"model_sft\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-10: 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model_sft\n",
    "model_sft = PeftModel.from_pretrained(\n",
    "    model=model_base,\n",
    "    model_id=os.path.join(path_model, \"model_sft\"),\n",
    "    is_trainable=False\n",
    ")\n",
    "model_sft = model_sft.merge_and_unload()  # W + BA, speed up, but errors when use 8-bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-11: 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
