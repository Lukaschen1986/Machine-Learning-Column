{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/trl/main/en/dpo_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRL supports the DPO Trainer for training language models from preference data, as described in the paper Direct Preference Optimization: Your Language Model is Secretly a Reward Model by Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, Chelsea Finn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U --user datasets accelerate peft trl tensorboard bitsandbytes langchain sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "\n",
    "from pprint import pp\n",
    "from datasets import (load_dataset, load_from_disk, Dataset)\n",
    "from transformers import (AutoTokenizer, AutoModel, AutoModelForCausalLM, BitsAndBytesConfig,\n",
    "                          TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForSeq2Seq, DataCollatorForTokenClassification)\n",
    "from peft import (LoraConfig, get_peft_model, PeftModel, TaskType, get_peft_model_state_dict)\n",
    "from trl import (DPOConfig, DPOTrainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda; devive_cnt = 1\n",
      "2.5.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "devive_cnt = th.cuda.device_count()\n",
    "print(f\"device = {device}; devive_cnt = {devive_cnt}\")\n",
    "print(th.__version__)\n",
    "print(th.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"C:/my_project/MyGit/Machine-Learning-Column/hugging_face\"\n",
    "path_data = os.path.join(os.path.dirname(path_project), \"data\")\n",
    "path_model = \"F:/LLM\"\n",
    "path_output = os.path.join(os.path.dirname(path_project), \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-1: 载入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"trl-lib/ultrafeedback_binarized/train-00000-of-00001.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    path=\"parquet\",\n",
    "    data_files=os.path.join(path_data, filename),\n",
    "    split=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(2000))\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=0) \n",
    "train_dataset, eval_dataset = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
       "     num_rows: 1600\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
       "     num_rows: 400\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chosen': [{'content': 'Please answer the following question: Question: Who '\n",
      "                        'seized the galley? If there is no answer, please '\n",
      "                        'output \"Insufficient information to provide an '\n",
      "                        'answer.\". Movie title: The Maltese Falcon Context: In '\n",
      "                        'San Francisco, private investigator Sam Spade '\n",
      "                        '(Ricardo Cortez) and his partner Miles Archer (Walter '\n",
      "                        'Long) are approached by Ruth Wonderly (Bebe Daniels) '\n",
      "                        'to follow a man, Floyd Thursby, who allegedly ran off '\n",
      "                        'with her younger sister. The two accept the '\n",
      "                        'assignment because the money is good, even though '\n",
      "                        'they disbelieve her story. Late that night, police '\n",
      "                        'detective Tom Polhaus (J. Farrell MacDonald) informs '\n",
      "                        'Spade that Archer has been shot and killed while '\n",
      "                        'tailing Thursby, but Spade turns down the opportunity '\n",
      "                        \"to examine the body at the scene. As he's leaving, he \"\n",
      "                        'has a brief conversation in Chinese with a man '\n",
      "                        'loitering in a doorway. Later, Polhaus and his '\n",
      "                        'superior, Lt. Dundy (Robert Elliott), visit Spade at '\n",
      "                        'his apartment. Thursby has been killed, and they want '\n",
      "                        \"to know where Spade's been in the last few hours \"\n",
      "                        'â\\x80\\x94 they suspect him of killing Thursby to '\n",
      "                        'avenge the death of his partner. With no real '\n",
      "                        'evidence against Spade, they leave. The next day, '\n",
      "                        'Spade calls on Ruth Wonderly in an attempt to find '\n",
      "                        'out her real reasons for hiring them. She uses '\n",
      "                        'several different ploys to keep Spade on the case in '\n",
      "                        'spite of the two murders, but Spade sees through '\n",
      "                        'them. Despite this, he gets only a little information '\n",
      "                        'from her: Thursby was her accomplice whom she no '\n",
      "                        \"longer trusted, and she feels she's in danger \"\n",
      "                        \"â\\x80\\x94 but she won't tell Spade what she and \"\n",
      "                        'Thursby were trying to pull off. Frustrated, Spade '\n",
      "                        'begins to leave, but then thinks better of it. He '\n",
      "                        'takes $500 from Wonderly, supposedly the last of her '\n",
      "                        'money, and goes. At the office, Spade tells his '\n",
      "                        \"secretary, Effie (Una Merkel) to have Archer's name \"\n",
      "                        'removed from the door, and he receives a visit from a '\n",
      "                        'Dr. Joel Cairo (Otto Matieson), who offers Spade '\n",
      "                        '$5,000 if he can retrieve an enamel figurine of a '\n",
      "                        'black bird that he is trying to recover for the '\n",
      "                        '\"rightful owner\". Not knowing anything about this '\n",
      "                        'statuette, Spade plays along, overpowering Cairo when '\n",
      "                        'he pulls a gun and attempts to frisk him and search '\n",
      "                        'the office. Nevertheless, he agrees to try to recover '\n",
      "                        'the statuette. That night, at his...\\n'\n",
      "                        'Answer:',\n",
      "             'role': 'user'},\n",
      "            {'content': 'Insufficient information to provide an answer.\\n'\n",
      "                        '\\n'\n",
      "                        'Confidence: 100%',\n",
      "             'role': 'assistant'}],\n",
      " 'rejected': [{'content': 'Please answer the following question: Question: Who '\n",
      "                          'seized the galley? If there is no answer, please '\n",
      "                          'output \"Insufficient information to provide an '\n",
      "                          'answer.\". Movie title: The Maltese Falcon Context: '\n",
      "                          'In San Francisco, private investigator Sam Spade '\n",
      "                          '(Ricardo Cortez) and his partner Miles Archer '\n",
      "                          '(Walter Long) are approached by Ruth Wonderly (Bebe '\n",
      "                          'Daniels) to follow a man, Floyd Thursby, who '\n",
      "                          'allegedly ran off with her younger sister. The two '\n",
      "                          'accept the assignment because the money is good, '\n",
      "                          'even though they disbelieve her story. Late that '\n",
      "                          'night, police detective Tom Polhaus (J. Farrell '\n",
      "                          'MacDonald) informs Spade that Archer has been shot '\n",
      "                          'and killed while tailing Thursby, but Spade turns '\n",
      "                          'down the opportunity to examine the body at the '\n",
      "                          \"scene. As he's leaving, he has a brief conversation \"\n",
      "                          'in Chinese with a man loitering in a doorway. '\n",
      "                          'Later, Polhaus and his superior, Lt. Dundy (Robert '\n",
      "                          'Elliott), visit Spade at his apartment. Thursby has '\n",
      "                          \"been killed, and they want to know where Spade's \"\n",
      "                          'been in the last few hours â\\x80\\x94 they suspect '\n",
      "                          'him of killing Thursby to avenge the death of his '\n",
      "                          'partner. With no real evidence against Spade, they '\n",
      "                          'leave. The next day, Spade calls on Ruth Wonderly '\n",
      "                          'in an attempt to find out her real reasons for '\n",
      "                          'hiring them. She uses several different ploys to '\n",
      "                          'keep Spade on the case in spite of the two murders, '\n",
      "                          'but Spade sees through them. Despite this, he gets '\n",
      "                          'only a little information from her: Thursby was her '\n",
      "                          'accomplice whom she no longer trusted, and she '\n",
      "                          \"feels she's in danger â\\x80\\x94 but she won't tell \"\n",
      "                          'Spade what she and Thursby were trying to pull off. '\n",
      "                          'Frustrated, Spade begins to leave, but then thinks '\n",
      "                          'better of it. He takes $500 from Wonderly, '\n",
      "                          'supposedly the last of her money, and goes. At the '\n",
      "                          'office, Spade tells his secretary, Effie (Una '\n",
      "                          \"Merkel) to have Archer's name removed from the \"\n",
      "                          'door, and he receives a visit from a Dr. Joel Cairo '\n",
      "                          '(Otto Matieson), who offers Spade $5,000 if he can '\n",
      "                          'retrieve an enamel figurine of a black bird that he '\n",
      "                          'is trying to recover for the \"rightful owner\". Not '\n",
      "                          'knowing anything about this statuette, Spade plays '\n",
      "                          'along, overpowering Cairo when he pulls a gun and '\n",
      "                          'attempts to frisk him and search the office. '\n",
      "                          'Nevertheless, he agrees to try to recover the '\n",
      "                          'statuette. That night, at his...\\n'\n",
      "                          'Answer:',\n",
      "               'role': 'user'},\n",
      "              {'content': 'Insufficient information to provide an answer.',\n",
      "               'role': 'assistant'}],\n",
      " 'score_chosen': 8.0,\n",
      " 'score_rejected': 8.0}\n"
     ]
    }
   ],
   "source": [
    "pp(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-2: tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "<|im_end|>\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.eos_token)\n",
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-3: 配置量化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=th.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")  # QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-4: 载入基模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=th.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",  # flash_attention_2, sdpa\n",
    "    # quantization_config=config_bnb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.gradient_checkpointing_enable()\n",
    "base_model.enable_input_require_grads()\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "if th.cuda.device_count() > 1:\n",
    "    base_model.is_parallelizable = True\n",
    "    base_model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已分配的GPU内存：2.88G, 已缓存的GPU内存：3.06G\n"
     ]
    }
   ],
   "source": [
    "allocated_memory = th.cuda.memory_allocated()\n",
    "cached_memory = th.cuda.memory_cached()\n",
    "print(f\"已分配的GPU内存：{allocated_memory / 1024**3:.2f}G, 已缓存的GPU内存：{cached_memory / 1024**3:.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_size = len(tokenizer)\n",
    "embedding_size = base_model.get_input_embeddings().weight.shape[0]\n",
    "if tokenizer_size > embedding_size:\n",
    "    base_model.resize_token_embeddings(tokenizer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-5: 配置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = DPOConfig(\n",
    "    output_dir=os.path.join(path_output, checkpoint + \"-DPO\"), \n",
    "    logging_steps=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPOConfig(output_dir='C:/my_project/MyGit/Machine-Learning-Column\\\\output\\\\Qwen/Qwen2.5-3B-Instruct-DPO',\n",
      "          overwrite_output_dir=False,\n",
      "          do_train=False,\n",
      "          do_eval=False,\n",
      "          do_predict=False,\n",
      "          eval_strategy=<IntervalStrategy.NO: 'no'>,\n",
      "          prediction_loss_only=False,\n",
      "          per_device_train_batch_size=8,\n",
      "          per_device_eval_batch_size=8,\n",
      "          per_gpu_train_batch_size=None,\n",
      "          per_gpu_eval_batch_size=None,\n",
      "          gradient_accumulation_steps=1,\n",
      "          eval_accumulation_steps=None,\n",
      "          eval_delay=0,\n",
      "          torch_empty_cache_steps=None,\n",
      "          learning_rate=1e-06,\n",
      "          weight_decay=0.0,\n",
      "          adam_beta1=0.9,\n",
      "          adam_beta2=0.999,\n",
      "          adam_epsilon=1e-08,\n",
      "          max_grad_norm=1.0,\n",
      "          num_train_epochs=3.0,\n",
      "          max_steps=-1,\n",
      "          lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>,\n",
      "          lr_scheduler_kwargs={},\n",
      "          warmup_ratio=0.0,\n",
      "          warmup_steps=0,\n",
      "          log_level='passive',\n",
      "          log_level_replica='warning',\n",
      "          log_on_each_node=True,\n",
      "          logging_dir='C:/my_project/MyGit/Machine-Learning-Column\\\\output\\\\Qwen/Qwen2.5-3B-Instruct-DPO\\\\runs\\\\Feb23_17-20-15_DESKTOP-D8ANG84',\n",
      "          logging_strategy=<IntervalStrategy.STEPS: 'steps'>,\n",
      "          logging_first_step=False,\n",
      "          logging_steps=10,\n",
      "          logging_nan_inf_filter=True,\n",
      "          save_strategy=<SaveStrategy.STEPS: 'steps'>,\n",
      "          save_steps=500,\n",
      "          save_total_limit=None,\n",
      "          save_safetensors=True,\n",
      "          save_on_each_node=False,\n",
      "          save_only_model=False,\n",
      "          restore_callback_states_from_checkpoint=False,\n",
      "          no_cuda=False,\n",
      "          use_cpu=False,\n",
      "          use_mps_device=False,\n",
      "          seed=42,\n",
      "          data_seed=None,\n",
      "          jit_mode_eval=False,\n",
      "          use_ipex=False,\n",
      "          bf16=False,\n",
      "          fp16=False,\n",
      "          fp16_opt_level='O1',\n",
      "          half_precision_backend='auto',\n",
      "          bf16_full_eval=False,\n",
      "          fp16_full_eval=False,\n",
      "          tf32=None,\n",
      "          local_rank=0,\n",
      "          ddp_backend=None,\n",
      "          tpu_num_cores=None,\n",
      "          tpu_metrics_debug=False,\n",
      "          debug=[],\n",
      "          dataloader_drop_last=False,\n",
      "          eval_steps=None,\n",
      "          dataloader_num_workers=0,\n",
      "          dataloader_prefetch_factor=None,\n",
      "          past_index=-1,\n",
      "          run_name='C:/my_project/MyGit/Machine-Learning-Column\\\\output\\\\Qwen/Qwen2.5-3B-Instruct-DPO',\n",
      "          disable_tqdm=False,\n",
      "          remove_unused_columns=True,\n",
      "          label_names=None,\n",
      "          load_best_model_at_end=False,\n",
      "          metric_for_best_model=None,\n",
      "          greater_is_better=None,\n",
      "          ignore_data_skip=False,\n",
      "          fsdp=[],\n",
      "          fsdp_min_num_params=0,\n",
      "          fsdp_config={'min_num_params': 0,\n",
      "                       'xla': False,\n",
      "                       'xla_fsdp_v2': False,\n",
      "                       'xla_fsdp_grad_ckpt': False},\n",
      "          fsdp_transformer_layer_cls_to_wrap=None,\n",
      "          accelerator_config=AcceleratorConfig(split_batches=False,\n",
      "                                               dispatch_batches=None,\n",
      "                                               even_batches=True,\n",
      "                                               use_seedable_sampler=True,\n",
      "                                               non_blocking=False,\n",
      "                                               gradient_accumulation_kwargs=None,\n",
      "                                               use_configured_state=False),\n",
      "          deepspeed=None,\n",
      "          label_smoothing_factor=0.0,\n",
      "          optim=<OptimizerNames.ADAMW_TORCH: 'adamw_torch'>,\n",
      "          optim_args=None,\n",
      "          adafactor=False,\n",
      "          group_by_length=False,\n",
      "          length_column_name='length',\n",
      "          report_to=['tensorboard'],\n",
      "          ddp_find_unused_parameters=None,\n",
      "          ddp_bucket_cap_mb=None,\n",
      "          ddp_broadcast_buffers=None,\n",
      "          dataloader_pin_memory=True,\n",
      "          dataloader_persistent_workers=False,\n",
      "          skip_memory_metrics=True,\n",
      "          use_legacy_prediction_loop=False,\n",
      "          push_to_hub=False,\n",
      "          resume_from_checkpoint=None,\n",
      "          hub_model_id=None,\n",
      "          hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>,\n",
      "          hub_token=None,\n",
      "          hub_private_repo=None,\n",
      "          hub_always_push=False,\n",
      "          gradient_checkpointing=False,\n",
      "          gradient_checkpointing_kwargs=None,\n",
      "          include_inputs_for_metrics=False,\n",
      "          include_for_metrics=[],\n",
      "          eval_do_concat_batches=True,\n",
      "          fp16_backend='auto',\n",
      "          evaluation_strategy=None,\n",
      "          push_to_hub_model_id=None,\n",
      "          push_to_hub_organization=None,\n",
      "          push_to_hub_token=None,\n",
      "          mp_parameters='',\n",
      "          auto_find_batch_size=False,\n",
      "          full_determinism=False,\n",
      "          torchdynamo=None,\n",
      "          ray_scope='last',\n",
      "          ddp_timeout=1800,\n",
      "          torch_compile=False,\n",
      "          torch_compile_backend=None,\n",
      "          torch_compile_mode=None,\n",
      "          dispatch_batches=None,\n",
      "          split_batches=None,\n",
      "          include_tokens_per_second=False,\n",
      "          include_num_input_tokens_seen=False,\n",
      "          neftune_noise_alpha=None,\n",
      "          optim_target_modules=None,\n",
      "          batch_eval_metrics=False,\n",
      "          eval_on_start=False,\n",
      "          use_liger_kernel=False,\n",
      "          eval_use_gather_object=False,\n",
      "          average_tokens_across_devices=False,\n",
      "          model_init_kwargs=None,\n",
      "          ref_model_init_kwargs=None,\n",
      "          model_adapter_name=None,\n",
      "          ref_adapter_name=None,\n",
      "          force_use_ref_model=False,\n",
      "          disable_dropout=True,\n",
      "          use_logits_to_keep=False,\n",
      "          dataset_num_proc=None,\n",
      "          padding_value=None,\n",
      "          label_pad_token_id=-100,\n",
      "          max_prompt_length=512,\n",
      "          max_completion_length=None,\n",
      "          max_length=1024,\n",
      "          truncation_mode='keep_end',\n",
      "          padding_free=False,\n",
      "          precompute_ref_log_probs=False,\n",
      "          precompute_ref_batch_size=None,\n",
      "          tools=None,\n",
      "          loss_type='sigmoid',\n",
      "          beta=0.1,\n",
      "          f_divergence_type=<FDivergenceType.REVERSE_KL: 'reverse_kl'>,\n",
      "          f_alpha_divergence_coef=1.0,\n",
      "          reference_free=False,\n",
      "          label_smoothing=0.0,\n",
      "          use_weighting=False,\n",
      "          rpo_alpha=None,\n",
      "          discopop_tau=0.05,\n",
      "          sync_ref_model=False,\n",
      "          ref_model_mixup_alpha=0.9,\n",
      "          ref_model_sync_steps=64,\n",
      "          generate_during_eval=False,\n",
      "          use_num_logits_to_keep=False)\n"
     ]
    }
   ],
   "source": [
    "pp(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-6: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c76098e04244c09e69d29dce2815ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27271b5427d482abcd7af5886487454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36ee689aabe464b86a5132bd2d9fefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db34c04674be4fb893c177103ffd6790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = DPOTrainer(\n",
    "    model=base_model,\n",
    "    # ref_model=None, \n",
    "    args=training_args, \n",
    "    # data_collator=None,  \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer\n",
    "    )\n",
    "# ref_model: If no reference model is provided, the trainer will create a reference model with the same architecture. ref_model = deepcopy(model)\n",
    "# data_collator: If None is specified, the default data collator (`DataCollatorForPreference`) will be used. data_collator = DataCollatorForPreference(pad_token_id=self.padding_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForPreference(pad_token_id=151643, return_tensors='pt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-7: 模型训练 (using unsloth on Linux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "model = FastLanguageModel.get_peft_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = DPOConfig(output_dir=\"Qwen2-0.5B-DPO\", logging_steps=10, bf16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DPOTrainer(\n",
    "    model=base_model,\n",
    "    # ref_model=None, \n",
    "    args=training_args, \n",
    "    # data_collator=None,  \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
