{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U --user datasets accelerate peft trl tensorboard bitsandbytes langchain sentencepiece transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "import transformers\n",
    "\n",
    "from pprint import pp\n",
    "from datasets import (load_dataset, load_from_disk, Dataset)\n",
    "from transformers import (AutoTokenizer, \n",
    "                          BitsAndBytesConfig,\n",
    "                          AutoModel, \n",
    "                          AutoModelForCausalLM, \n",
    "                          AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding, \n",
    "                          DataCollatorForLanguageModeling,\n",
    "                          DataCollatorForSeq2Seq, \n",
    "                          DataCollatorForTokenClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "from peft import (LoraConfig, get_peft_model, PeftModel, TaskType, get_peft_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda; devive_cnt = 1\n",
      "torch version = 2.5.1+cu121\n",
      "cuda version = 12.1\n",
      "transformers version = 4.49.0\n"
     ]
    }
   ],
   "source": [
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "devive_cnt = th.cuda.device_count()\n",
    "print(f\"device = {device}; devive_cnt = {devive_cnt}\")\n",
    "print(f\"torch version = {th.__version__}\")\n",
    "print(f\"cuda version = {th.version.cuda}\")\n",
    "print(f\"transformers version = {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"C:/my_project/MyGit/Machine-Learning-Column/hugging_face\"\n",
    "path_data = os.path.join(os.path.dirname(path_project), \"data\")\n",
    "path_model = \"F:/LLM\"\n",
    "path_output = os.path.join(os.path.dirname(path_project), \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-1: 载入数据源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"HuggingFaceFW/fineweb/000_00000.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fc4666bcc249a1b7e16dee273bfb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    path=\"parquet\",\n",
    "    data_files=os.path.join(path_data, filename),\n",
    "    split=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(200))\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=0) \n",
    "train_dataset, eval_dataset = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Well, this 2020 spring sure snuck up on us. Down here in the southwest, the temps are getting into the 70s already in March, so we are looking at some DIY projects. We have decided that an DIY outdoor kitchen is what my father-in-law’s backyard needs. He’s super excited and we started talking and discussing the build and what we would want in the structure.\\nWe have a few hundred square feet to work with, so we have some different shapes and configurations available to us. There is a gorgeous mountain view to our east, so we definitely want to keep that on our mind when we design the layout.\\nFirst and foremost, my father-in-law loves to cook on charcoal, so we are headed in that direction with the grill. We picked out a Char-Broil brand structure that we’ll modify to fit the space. That’s a real cool way to build and very economical, so we’ll be getting into that in some future posts. Secondly, we are looking to match the exterior of the outdoor fireplace that we built last year on the opposite side of the backyard. In order to do that, we’ll be putting stucco and outdoor lighting on our DIY outdoor kitchen, with flagstone as our counter material. By using the same finish material on the grill and fireplace, it’ll look like we built both structures at the same time and the overall look of the backyard will look well thought out.\\nWe decided that a raised bar area would be a nice addition to the DIY outdoor kitchen, so the structure will have to be big enough to accommodate that extra feature. An “L” shape is something we feel will work so the guests sitting at the bar will have the mountain view to look at while they talk to the grill chef and enjoy their favorite beverage.\\nStarting the Construction\\nWe staked out the rough dimension of the “L” shape grill and then started figuring out the level of the future concrete slab. This is important so our patio pavers are the same height of the patio to the house. The excavation of the site started with a quick dig out of the slab dimension.\\nUsing a really long level, 6-footer, we laid out random pavers from the existing patio to the farthest side of the DIY outdoor kitchen structure. This would tell us how much digging we would need to do to get it uniform and level.\\nDrawing and Block Count/Order\\nDan at Backyard Flare drew up the grill structure using CAD and concept and then used the drawing to calculate the type of blocks and exact number of each block needed. Dan figured the mortar and concrete need as well, and then called Lowes to place the order for delivery. The best part is that almost all the building materials and even the grill will be delivered right to the side of the house, which is where the gate is located leading to the backyard. The materials purchased, including the $75 delivery fee, was only $505, and that included the grill. Wow, how much more economical can it get?\\nFollow along on our future posts as we build. You’ll be amazed at how easy and inexpensive it can actually be to build on your own. The DIY world is yours to explore and we can help. If you’re interested in building your own backyard paradise, let us know how we can help. Get your construction plan today and begin building your DIY outdoor kitchen tomorrow. Happy building.',\n",
       " 'id': '<urn:uuid:698b1181-8889-4141-9d2c-d018d06d32cc>',\n",
       " 'dump': 'CC-MAIN-2024-51',\n",
       " 'url': 'http://www.diyoutdoorfireplaces.com/tag/grilling/',\n",
       " 'date': '2024-12-01T18:33:04Z',\n",
       " 'file_path': 's3://commoncrawl/crawl-data/CC-MAIN-2024-51/segments/1733066035857.0/warc/CC-MAIN-20241201162023-20241201192023-00000.warc.gz',\n",
       " 'language': 'en',\n",
       " 'language_score': 0.963820219039917,\n",
       " 'token_count': 721}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-2: tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Qwen/Qwen2.5-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "<|im_end|>\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.eos_token)\n",
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-3: 配置量化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bnb = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=th.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")  # QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step-4: 载入基模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4004de8979840d98d1948640e13646e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.path.join(path_model, checkpoint),\n",
    "    cache_dir=path_model,\n",
    "    force_download=False,\n",
    "    local_files_only=True,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=th.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",  # flash_attention_2, sdpa\n",
    "    quantization_config=config_bnb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.gradient_checkpointing_enable()\n",
    "base_model.enable_input_require_grads()\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "if th.cuda.device_count() > 1:\n",
    "    base_model.is_parallelizable = True\n",
    "    base_model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocated_memory = th.cuda.memory_allocated()\n",
    "cached_memory = th.cuda.memory_cached()\n",
    "print(f\"已分配的GPU内存：{allocated_memory / 1024**3:.2f}G, 已缓存的GPU内存：{cached_memory / 1024**3:.2f}G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_size = len(tokenizer)\n",
    "embedding_size = base_model.get_input_embeddings().weight.shape[0]\n",
    "if tokenizer_size > embedding_size:\n",
    "    base_model.resize_token_embeddings(tokenizer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
